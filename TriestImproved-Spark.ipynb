{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fileName = roadNet-CA/out.roadNet-CA\n",
       "graphRDD = MapPartitionsRDD[11] at map at <console>:62\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "lastException: Throwable = null\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[11] at map at <console>:62"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.graphx._\n",
    "import org.apache.spark._\n",
    "import org.apache.spark.rdd.RDD\n",
    "import scala.collection.mutable.ArrayBuffer\n",
    "import scala.io.Source\n",
    "import java.util.Random\n",
    "import scala.math.max\n",
    "\n",
    "val fileName = \"roadNet-CA/out.roadNet-CA\"\n",
    "val graphRDD = sc.textFile(fileName)\n",
    "    .zipWithIndex\n",
    "    .map(row => (row._2, row._1.split(\" \")\n",
    "         .map(item => item.toInt)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var S = ArrayBuffer.empty[List[Int]]\n",
    "val random = new Random()\n",
    "//var tau = 0.0\n",
    "//var t = 0\n",
    "val M = 100\n",
    "\n",
    "def updateCounters(op: Int, t:Int, edge:List[Int]): Float = {\n",
    "    val neighborhood_1 = S.filter(item => item(0) == edge(0)).map(item => item(1)).toSet\n",
    "    val neighborhood_2 = S.filter(item => item(0) == edge(1)).map(item => item(1)).toSet\n",
    "    val common_neighbors = neighborhood_1.intersect(neighborhood_2)\n",
    "    val temp = max(1, (t - 1)*(t - 2)/(M * (M - 1)))\n",
    "    tau = tau + op * common_neighbors.size + temp\n",
    "    tau\n",
    "}\n",
    "\n",
    "def FlipBiasedCoin(prob: Float): Boolean = {\n",
    "    return random.nextFloat() < prob\n",
    "}\n",
    "def ReservoirSample(t: Int, M: Int, e: List[Int]): Boolean = {\n",
    "\n",
    "    if(t <= M) {\n",
    "        return true\n",
    "    }\n",
    "    else if(FlipBiasedCoin(M.toFloat/t) == true){\n",
    "        val r = new scala.util.Random()\n",
    "        val randomEdgeIndex = r.nextInt(M)\n",
    "        val randomEdge = S(randomEdgeIndex)\n",
    "        S.remove(randomEdgeIndex)\n",
    "//         updateCounters(-1, randomEdge)\n",
    "        return true\n",
    "    }\n",
    "    return false\n",
    "}\n",
    "\n",
    "graphRDD.map(edge =>{\n",
    "    //t = t+1  ---t is embedded in the row to facilitate parallel computation\n",
    "    updateCounters(1, edge._1 edge._2)\n",
    "    if( ReservoirSample(t, M, e) ) {\n",
    "        S += e\n",
    "    }\n",
    "})\n",
    "S.foreach(println)\n",
    "println(tau)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark - Scala",
   "language": "scala",
   "name": "spark_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
