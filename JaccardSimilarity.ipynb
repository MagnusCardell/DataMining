{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows the implementation of different algorithms related to finding textually similar documents. Based on Jaccard similarity, we implement shingling, minhashing, and locality-sensitive hashing (LHS). \n",
    "\n",
    "Using a collection of NSF research award abstracts obtained from https://archive.ics.uci.edu/ml/datasets/NSF+Research+Award+Abstracts+1990-2003 we produce a collection of vectors containing hashed shingles based on k-grams of size 5 hashed using MurmurHash. We then use minhash with 100 different hashing algorithms by randomly generating coefficients. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fileName1 = dataset_abstracts/a9000038.txt\n",
       "fileName2 = dataset_abstracts/a9000040.txt\n",
       "rows1 = MapPartitionsRDD[2] at map at <console>:31\n",
       "text1 = Title : Mathematical Sciences: Research on Optimal Stochastic Control and NonlinearEstimationType : AwardNSF Org : DMSLatestAmendmentDate : April 8, 1992File : a9000038Award Number: 9000038Award Instr.: Continuing grantPrgm Manager:DMS DIVISION OF MATHEMATICAL SCIENCESMPS DIRECT FOR MATHEMATICAL & PHYSICAL SCIENStart Date : July 1, 1990Expires : December 31, 1993 (Estimated)ExpectedTotal Amt. : $188574 (Estimated)Investigator: Wendell H. Fleming whf@cfm.brown.edu (Principal Investigator current)Sponsor : Brown University164 Angell StreetProvidence, RI 02912 401/863-2777NSF Program : 1266...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Title : Mathematical Sciences: Research on Optimal Stochastic Control and NonlinearEstimationType : AwardNSF Org : DMSLatestAmendmentDate : April 8, 1992File : a9000038Award Number: 9000038Award Instr.: Continuing grantPrgm Manager:DMS DIVISION OF MATHEMATICAL SCIENCESMPS DIRECT FOR MATHEMATICAL & PHYSICAL SCIENStart Date : July 1, 1990Expires : December 31, 1993 (Estimated)ExpectedTotal Amt. : $188574 (Estimated)Investigator: Wendell H. Fleming whf@cfm.brown.edu (Principal Investigator current)Sponsor : Brown University164 Angell StreetProvidence, RI 02912 401/863-2777NSF Program : 1266..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//input\n",
    "val fileName1 = \"dataset_abstracts/a9000038.txt\"\n",
    "val fileName2 = \"dataset_abstracts/a9000040.txt\"\n",
    "\n",
    "val rows1 = sc.textFile(fileName1).map(line=>line.trim().replaceAll(\"(\\\\s)+\", \" \")).cache()\n",
    "val text1 = rows1.reduce(_ + _)\n",
    "\n",
    "val rows2 = sc.textFile(fileName2).map(line=>line.trim().replaceAll(\"(\\\\s)+\", \" \")).cache()\n",
    "val text2 = rows2.reduce(_ + _)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "k = 5\n",
       "k_gram1 = List((-1874370966,\"\"), (1388959843,\"\"), (-867864100,\"\"), (-317192946,\"\"), (-671188304,\"\"), (1529582140,\"\"), (2071593523,\"\"), (-347942801,\"\"), (-96038573,\"\"), (1131329007,\"\"), (2139931382,\"\"), (-1615723425,\"\"), (495118698,\"\"), (-2011491347,\"\"), (-1361060683,\"\"), (834301842,\"\"), (1335086780,\"\"), (-954345614,\"\"), (179541937,\"\"), (1490961429,\"\"), (-1847526272,\"\"), (1142132048,\"\"), (-938932799,\"\"), (1873655578,\"\"), (2035819669,\"\"), (79787119,\"\"), (949560031,\"\"), (-147311775,\"\"), (-1920259009,\"\"), (338189782,\"\"), (-1661430351,\"\"), (-320725340,\"\"), (1013651795,\"\"), (-7031774,\"\"), (-274139822,\"\"), (-921542000,\"\"), (-1675875172,\"\"), (-2115819354,\"\"), (857143427,\"\"), (-1815694727,\"\"), (1907031089,\"\"), (1231827076,\"\"), (-1156846470,\"\"), (-1356510284,\"\"), (...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "List((-1874370966,\"\"), (1388959843,\"\"), (-867864100,\"\"), (-317192946,\"\"), (-671188304,\"\"), (1529582140,\"\"), (2071593523,\"\"), (-347942801,\"\"), (-96038573,\"\"), (1131329007,\"\"), (2139931382,\"\"), (-1615723425,\"\"), (495118698,\"\"), (-2011491347,\"\"), (-1361060683,\"\"), (834301842,\"\"), (1335086780,\"\"), (-954345614,\"\"), (179541937,\"\"), (1490961429,\"\"), (-1847526272,\"\"), (1142132048,\"\"), (-938932799,\"\"), (1873655578,\"\"), (2035819669,\"\"), (79787119,\"\"), (949560031,\"\"), (-147311775,\"\"), (-1920259009,\"\"), (338189782,\"\"), (-1661430351,\"\"), (-320725340,\"\"), (1013651795,\"\"), (-7031774,\"\"), (-274139822,\"\"), (-921542000,\"\"), (-1675875172,\"\"), (-2115819354,\"\"), (857143427,\"\"), (-1815694727,\"\"), (1907031089,\"\"), (1231827076,\"\"), (-1156846470,\"\"), (-1356510284,\"\"), (..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//k-gram\n",
    "val k = 5\n",
    "val k_gram1 = text1.split(\"\").sliding(k).toList.map(x => (scala.util.hashing.MurmurHash3.arrayHash(x), \"\"))\n",
    "val kgramRDD1 = sc.parallelize(k_gram1)\n",
    "val filtered1 = kgramRDD1.distinct()\n",
    "\n",
    "val k_gram2 = text2.split(\"\").sliding(k).toList.map(x => (scala.util.hashing.MurmurHash3.arrayHash(x), \"\"))\n",
    "val kgramRDD2 = sc.parallelize(k_gram2)\n",
    "val filtered2 = kgramRDD2.distinct()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6185781\n",
      "0.38142192\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "join = MapPartitionsRDD[16] at leftOuterJoin at <console>:28\n",
       "join_n = 1192.0\n",
       "union = MapPartitionsRDD[20] at distinct at <console>:30\n",
       "union_n = 1927.0\n",
       "sim = 0.6185781\n",
       "jacc_dist = 0.38142192\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.38142192"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "val join = filtered1.leftOuterJoin(filtered2)\n",
    "val join_n = join.count().toFloat\n",
    "val union = filtered1.union(filtered2).distinct()\n",
    "val union_n = union.count().toFloat\n",
    "\n",
    "val sim = join_n / union_n\n",
    "val jacc_dist = 1-sim\n",
    "\n",
    "println(sim)\n",
    "println(jacc_dist)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we work with Min-hashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(a9000038.txt,Title : Mathematical Sciences: Research on Optimal Stochastic Control and Nonlinear EstimationType : AwardNSF Org : DMS LatestAmendmentDate : April 8, 1992 File : a9000038Award Number: 9000038Award Instr.: Continuing grant Prgm Manager:  DMS DIVISION OF MATHEMATICAL SCIENCES  MPS DIRECT FOR MATHEMATICAL & PHYSICAL SCIENStart Date : July 1, 1990 Expires : December 31, 1993 (Estimated)ExpectedTotal Amt. : $188574 (Estimated)Investigator: Wendell H. Fleming whf@cfm.brown.edu (Principal Investigator current)Sponsor : Brown University 164 Angell Street Providence, RI 02912 401/863-2777NSF Program : 1266 APPLIED MATHEMATICSFld Applictn: 0000099 Other Applications NEC  21 Mathematics Program Ref : Abstract : This research is part of an on-going program by the  principal investigator and associates. Topics in the following  areas are to be considered: (1) controlled Markov diffusions  and nonlinear PDEs; (2) asymptotic properties of nearly  deterministic Markov processes; (3) financial economics  applications; (4) singular stochastic control; (5) computational  methods in stochastic control; (6) stochastic calculus of  variations; (7) nonlinear estimation. Analytical methods based  on viscosity solution techniques for nonlinear differential  equations as well as probabilistic methods will be studied.  These theoretical studies are the basis for applied problems  ranging from decisions at the stock market level to the control  of spaceships.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dir = dataset_abstracts\n",
       "files = Array(dataset_abstracts/a9000038.txt, dataset_abstracts/a9000040.txt, dataset_abstracts/a9000043.txt, dataset_abstracts/a9000045.txt, dataset_abstracts/a9000046.txt, dataset_abstracts/a9000048.txt, dataset_abstracts/a9000049.txt, dataset_abstracts/a9000050.txt, dataset_abstracts/a9000052.txt, dataset_abstracts/a9000053.txt, dataset_abstracts/a9000054.txt, dataset_abstracts/a9000057.txt, dataset_abstracts/a9000058.txt, dataset_abstracts/a9000060.txt, dataset_abstracts/a9000063.txt, dataset_abstracts/a9000075.txt, dataset_abstracts/a9000089.txt, dataset_abstracts/a9000091.txt, dataset_abstracts/a9000094.txt, dataset_abstracts/a9000099.txt, dataset_abstracts/a9000100.txt, dataset_abstracts/a9000102.txt, ...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Array(dataset_abstracts/a9000038.txt, dataset_abstracts/a9000040.txt, dataset_abstracts/a9000043.txt, dataset_abstracts/a9000045.txt, dataset_abstracts/a9000046.txt, dataset_abstracts/a9000048.txt, dataset_abstracts/a9000049.txt, dataset_abstracts/a9000050.txt, dataset_abstracts/a9000052.txt, dataset_abstracts/a9000053.txt, dataset_abstracts/a9000054.txt, dataset_abstracts/a9000057.txt, dataset_abstracts/a9000058.txt, dataset_abstracts/a9000060.txt, dataset_abstracts/a9000063.txt, dataset_abstracts/a9000075.txt, dataset_abstracts/a9000089.txt, dataset_abstracts/a9000091.txt, dataset_abstracts/a9000094.txt, dataset_abstracts/a9000099.txt, dataset_abstracts/a9000100.txt, dataset_abstracts/a9000102.txt, ..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import java.io.File\n",
    "\n",
    "val dir = new File(\"dataset_abstracts\")\n",
    "val files = dir.listFiles() //379\n",
    "val maxSize = 10\n",
    "val docSize = if(files.size < maxSize) files.size else maxSize\n",
    "\n",
    "val docs = files.map(f => (f.getName(), sc.textFile(f.getPath() ).map(line=>line.replaceAll(\"(\\\\s)+\", \" \")).collect().reduce(_ + _)))\n",
    "val docsRDD = sc.parallelize(docs).cache()\n",
    "println(docsRDD.take(1)(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MapPartitionsRDD[1156] at map at <console>:34\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "abstracts = MapPartitionsRDD[1155] at map at <console>:30\n",
       "k = 5\n",
       "k_gram = MapPartitionsRDD[1156] at map at <console>:34\n",
       "documents = MapPartitionsRDD[1157] at map at <console>:36\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[1157] at map at <console>:36"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val abstracts = docsRDD.map(doc => (doc._1,doc._2.split(\"Abstract :\"))).filter(a => a._2.size > 1).map(a => (a._1, a._2(1)))\n",
    "\n",
    "//TODO RDD[ RDD [String]] --> RDD[(docId, shingle)]\n",
    "val k = 5\n",
    "val k_gram = abstracts.map(a => (a._1, a._2.split(\"\").sliding(k).toList.map(x => scala.util.hashing.MurmurHash3.arrayHash(x))))\n",
    "println(k_gram)\n",
    "val documents = k_gram.map(k => (k._1, k._2.distinct))\n",
    "//val kgramRDD = sc.parallelize(kgram_flat)\n",
    "//println(documents.take(1)(0))\n",
    "//val filtered = kgram_flat.groupByKey().map(a => a._2.unique)\n",
    "//println(filtered.take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector(MapPartitionsRDD[1213] at map at <console>:55)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "p = 1073676287\n",
       "m = 1073676288\n",
       "n = 2\n",
       "hash_algos = Vector((495872699,215764588), (496449823,630021372))\n",
       "doc_signatures = Vector(MapPartitionsRDD[1213] at map at <console>:55, MapPartitionsRDD[1214] at map at <console>:55)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "hashThis: (a: Long, b: Long, x: Long)Long\n",
       "generateRandomHashFunc: (i: Int)(Long, Long)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Vector(MapPartitionsRDD[1213] at map at <console>:55, MapPartitionsRDD[1214] at map at <console>:55)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Min-hashing\n",
    "\n",
    "val p = 1073676287\n",
    "val m = p + 1\n",
    "def hashThis(a:Long, b:Long, x:Long): Long = {\n",
    "    ((a*x + b) % p ) % m\n",
    "}\n",
    "def generateRandomHashFunc(i:Int): (Long, Long) = {\n",
    "    val r = new scala.util.Random(i)\n",
    "    val a2 = r.nextInt(p-1)\n",
    "    val a = if(a2%2==0) a2+1 else a2\n",
    "    val b = r.nextInt(p-1)\n",
    "    (a, b)\n",
    "}\n",
    "//var doc_signatures:List[List[(String, Long)]] = List.empty[List[(String, Long)]]\n",
    "\n",
    "val n = 2\n",
    "val hash_algos = (1 to n).map(i => generateRandomHashFunc(i))\n",
    "val doc_signatures = hash_algos.map(h => {\n",
    "    val min = documents.map(doc => (doc._1, doc._2.map(s => s.toLong).reduce((x,y) => hashThis(h._1, h._2, x) min hashThis(h._1, h._2, y) )))\n",
    "    min\n",
    "})\n",
    "println(doc_signatures.take(1))\n",
    "\n",
    "\n",
    "//compare signatures between different hashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for(i<-0 to 1){\n",
    "    \n",
    "    val r = new scala.util.Random(i)\n",
    "    val a2 = r.nextInt(p-1)\n",
    "    val a = if(a2%2==0) a2+1 else a2\n",
    "    val b = r.nextInt(p-1)\n",
    "    \n",
    "    val min = documents.map(doc => (doc._1, doc._2.map(s => s.toLong).reduce((x,y) => hashThis(a, b, x) min hashThis(a, b, y) )))\n",
    "    println(min.take(1)(0))\n",
    "    //val min = filtered1.map(s => s._1.toLong).reduce((x,y) => hashThis(a, b, x) min hashThis(a, b, y) )\n",
    "    \n",
    "    //min.map(m => doc_signature :+ m)\n",
    "    val collection = min.collect().toList\n",
    "    doc_signatures = doc_signatures :+ collection\n",
    "}\n",
    "\n",
    "val docSignatures = hm.map { case (key,value) =>\n",
    "  for (i <- 0 until value) {\n",
    "    new MyObject(key, \"a string\", i)\n",
    "  }}.toSeq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark - Scala",
   "language": "scala",
   "name": "spark_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
